import os
import numpy as np
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
from xgboost import XGBClassifier

# Define the CNN architecture
class FeatureExtractorCNN(nn.Module):
    def __init__(self):
        super(FeatureExtractorCNN, self).__init__()
        self.model = nn.Sequential(
            # Block 1
            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: (Batch, 32, 32, 32)
            
            # Block 2
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: (Batch, 64, 16, 16)
            
            # Block 3
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: (Batch, 128, 8, 8)
            
            # Flatten
            nn.Flatten(),
            
            # Fully Connected Layer
            nn.Linear(128 * 8 * 8, 256),  # Adjust based on input size
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 128),  # Final feature vector size
            nn.ReLU()
        )
    
    def forward(self, x):
        return self.model(x)

# Function to preprocess the input image
def preprocess_image(image_path, target_size=(64, 64)):
    transform = transforms.Compose([
        transforms.Resize(target_size),  # Resize to fixed size
        transforms.Grayscale(num_output_channels=1),  # Convert to grayscale
        transforms.ToTensor(),  # Convert to tensor
        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize
    ])
    image = Image.open(image_path).convert('RGB')
    return transform(image).unsqueeze(0)  # Add batch dimension

# Function to load the trained models
def load_models(cnn_model_path, xgb_model_path, device):
    # Load the CNN model
    cnn_model = FeatureExtractorCNN().to(device)
    cnn_model.load_state_dict(torch.load(cnn_model_path, map_location=device))
    cnn_model.eval()  # Set to evaluation mode
    
    # Load the XGBoost model
    xgb_model = XGBClassifier()
    xgb_model.load_model(xgb_model_path)
    
    return cnn_model, xgb_model

# Function to predict the class of a single image
def predict_single_image(image_path, cnn_model, xgb_model, device):
    # Preprocess the image
    image_tensor = preprocess_image(image_path).to(device)
    
    # Extract features using the CNN
    with torch.no_grad():
        features = cnn_model(image_tensor).cpu().numpy()
    
    # Predict the class using XGBoost
    prediction = xgb_model.predict(features)[0]
    return prediction

# Main function
if __name__ == "__main__":
    # Paths to the trained models
    cnn_model_path = "path/to/trained_cnn.pth"
    xgb_model_path = "path/to/trained_xgboost.json"
    
    # Path to the input image
    image_path = "path/to/input_image.png"
    
    # Device configuration (GPU or CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Load the models
    cnn_model, xgb_model = load_models(cnn_model_path, xgb_model_path, device)
    
    # Predict the class of the input image
    predicted_class = predict_single_image(image_path, cnn_model, xgb_model, device)
    print(f"Predicted Class: {predicted_class}")